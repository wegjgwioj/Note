# 1 视频学习
 打基础+面经 -=> LLM岗位必备技能
# 2 hello agent项目学完 datawhale社区
   Agent
# 3 项目实战

这个组合完美覆盖了计算机硕士求职大模型岗位的“黄金三角”：

1. **SmartCut** ➡ 证明**工程落地能力**（Go高并发 + 多模态处理）。
2. **报价 Agent** ➡ 证明**业务理解与复杂逻辑编排能力**（Agent + Function Calling）。
3. **微调项目（待定）** ➡ 证明**算法与模型调优能力**（SFT + 数据闭环）。---延续报价Agent

这样的简历，既能投“AI应用层”岗位，也能投“大模型算法层”岗位，容错率极高。

下面我针对前两个项目给你做**简历话术精修**，并为你**量身定制第三个微调项目**（这是决定你薪资上限的关键）。

---

### 🔨 项目一：SmartCut —— 语义化智能视频剪辑引擎

**点评：** 这是一个非常好的**全栈+AI**项目。最大的亮点是解决了 Python 在计算密集型任务中的性能瓶颈。

**简历优化建议（不仅要写做什么，要写解决了什么难点）：**

* **架构亮点：** 不要只写“Go调度 + Python执行”。要强调 **“生产者-消费者模型”**。
* *话术：* “设计基于 Redis 的 **生产者-消费者模型**，Go 作为高性能网关负责请求接收与鉴权，通过任务分发机制调度 Python Worker 集群，彻底解耦 I/O 密集型（Web）与 计算密集型（AI推理）任务。”


* **多模态对齐：** 这是面试官最感兴趣的算法点。
* *话术：* “实现 **跨模态语义对齐算法**：利用 Whisper 提取时间轴字幕，结合 LLM 的语义理解能力提取关键片段（Highlight Extraction），并将自然语言指令映射为 FFmpeg 剪辑参数，实现‘说话即剪辑’。”


* **显存管理（加分项）：** 如果你面试的是大厂基架组。
* *话术：* “设计 **显存锁（VRAM Mutex）** 机制，防止多个 Python Worker 同时加载大模型导致 GPU OOM（显存溢出），优化了单卡并发推理效率。”



---

### 🤖 项目二：自动报价核算 AI Agent

**点评：** 这个项目非常“落地”，属于 B2B 领域的 Vertical Agent（垂直智能体）。它的难点在于**“结构化输出”**和**“复杂计算”**，因为 LLM 数学很差，不能让它直接算，必须让它**调用工具**。

**简历优化建议（强调 Agent 思维）：**

* **核心痛点解决：** 强调 LLM 不擅长计算，所以你用了 Tool Use。
* *话术：* “针对 LLM 数学计算幻觉问题，构建 **ReAct (Reasoning + Acting)** 智能体架构。模型仅负责‘意图识别’与‘参数提取’（如提取 BOM、良率），计算逻辑下沉至 Python 算子（Pandas/Numpy），确保金额精确到小数点后两位。”


* **复杂逻辑编排：** 强调你如何处理复杂的 excel 结构。
* *话术：* “设计 **动态 Schema 解析器**，支持非结构化 Excel 数据到结构化 JSON 的自动映射。利用 **CoT (思维链)** 技术，引导模型分步思考（先确定工艺路线 -> 再匹配材料成本 -> 最后计算折旧），使复杂报价准确率提升至 95% 以上。”



---

### 🔥 项目三：微调项目（定胜负的关键）

前两个项目都是“调包”和“应用”。为了拿下 JD 4/5/6 这种高薪算法岗，你需要一个**Deep Dive（深度钻研）**的微调项目。

**我为你推荐：Vertical Domain SQL-Coder (垂直领域 Text-to-SQL 微调)**

**为什么选这个？**

1. **数据好找：** 开源的 Spider 数据集，或者你自己造几十条“公司数据库查询”数据。
2. **指标硬核：** 不看玄学的“通顺度”，只看 **Execution Accuracy (执行准确率)**。生成的 SQL 能跑通且结果对，就是牛逼。
3. **符合趋势：** “大模型 + 数据平台”是目前最火的 B 端应用方向（参考你的 JD 3）。

**项目名称：DB-Copilot —— 基于指令微调的垂直领域 Text-to-SQL 生成模型**

**技术栈：** Llama-3-8B (或 Qwen2-7B), Unsloth (加速微调), Peft (LoRA), SwanLab/W&B (可视化), vLLM.

**简历包装话术（直接抄作业）：**

* **项目定位：** 针对通用大模型在特定业务数据库（Schema）下 SQL 生成准确率低的问题，基于 **Llama-3-8B** 进行 **SFT (监督微调)**，构建企业级自然语言转 SQL 引擎。
* **数据闭环建设（核心 JD 要求）：**
* “构建包含 2000+ 条‘Text-QA-SQL’对的高质量指令微调数据集。使用 **Self-Instruct** 方法，利用 GPT-4 自动增强数据多样性（Data Augmentation），解决训练数据稀缺问题。”


* **高效微调（PEFT）：**
* “采用 **QLoRA (4-bit Quantization + LoRA)** 技术，在单卡 24G 显存下完成 8B 模型全参数微调。对比全量微调，训练速度提升 4 倍，显存占用降低 60%，且效果保持 98%。”


* **Schema 链接增强：**
* “针对‘幻觉字段’问题（模型编造不存在的列名），在 Prompt 中引入 **Schema Linking** 策略，强制模型先理解 Table Schema 再生成 SQL，在 Spider 数据集上的执行准确率（Execution Accuracy）从基座的 65% 提升至 82%。”



---

### 🚀 导师的最终“作战计划”

**第一周（现在）：冲刺项目二（Agent）。**

* 不要好高骛远。先把我们在上文讨论的 `langchain_agent.py` 跑通。
* 把“计算器”改成“报价计算器”。工具函数从 `eval()` 改成 `calculate_material_cost(bom_list)`。

**第二周：冲刺项目一（SmartCut）。**

* 重点是写那个 Go 的 Worker Pool 和 Python 的接口。

**第三周：攻克项目三（微调）。**

* 这是最难的。到时候我会教你用 `Unsloth` 或 `Llama-Factory`，那是目前最傻瓜化的微调工具，哪怕你以前没训过模型也能上手。

**你要先从哪个开始落地？如果我是你，我会趁热打铁，先把刚才的 LangChain 代码改成“报价 Agent”的雏形！**